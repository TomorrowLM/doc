---
slug: 构建工具
title: 构建工具
description: description.
category: 构建工具
date: 25-September-2020
---

# 构建工具

## 模块化

### CommonJS

是一种为JS的表现指定的规范，它希望js可以运行在任何地方，更多的说的是服务端模块规范，Node.js采用了这个规范。

核心思想
允许模块通过 `require` 方法来同步加载所要依赖的其他模块，然后通过 `exports` 或 `module.exports` 来导出需要暴露的接口。

**优点：**服务器端模块重用，NPM中模块包多，有将近20万个。

**缺点：**加载模块是同步的，只有加载完成后才能执行后面的操作，也就是当要用到该模块了，现加载现用，不仅加载速度慢，而且还会导致性能、可用性、调试和跨域访问等问题。Node.js主要用于服务器编程，加载的模块文件一般都存在本地硬盘，加载起来比较快，不用考虑异步加载的方式，因此,CommonJS规范比较适用。然而，这并不适合在浏览器环境，同步意味着阻塞加载，浏览器资源是异步加载的，因此有了AMD CMD解决方案。

**实现**：

- 服务器端的 [Node.js](http://www.nodejs.org/)
- [Browserify](http://browserify.org/)，浏览器端的 CommonJS 实现，可以使用 NPM 的模块，但是编译打包后的文件体积可能很大
- [modules-webmake](https://github.com/medikoo/modules-webmake)，类似Browserify，还不如 Browserify 灵活
- [wreq](https://github.com/substack/wreq)，Browserify 的前身

### **AMD**

鉴于浏览器的特殊情况，又出现了一个规范，这个规范呢可以实现异步加载依赖模块，并且会提前加载那就是AMD规范。

**其核心接口是**：define(id, 『dependencies』, factory) ，它要在声明模块的时候指定所有的依赖 dependencies ，并且还要当做形参传到factory 中，对于依赖的模块**提前执行**，**依赖前置**。

```js
define("module", ["dep1", "dep2"], function(d1, d2) {
  return someExportedValue;
});
require(["module", "../file"], function(module, file) { /* ... */ });
```

**优点：**在浏览器环境中异步加载模块；并行加载多个模块；

**缺点：**开发成本高，代码的阅读和书写比较困难，模块定义方式的语义不顺畅；不符合通用的模块化思维方式，是一种妥协的实现；

### **CMD**

Common Module Definition 规范和 AMD 很相似，尽量保持简单，并与 CommonJS 和 Node.js 的 Modules 规范保持了很大的兼容性。

```text
define(function(require, exports, module) {
  var $ = require('jquery');
  var Spinning = require('./spinning');
  exports.doSomething = ...
  module.exports = ...
})
```

**优点：依赖就近，延迟执行**（对于依赖的模块延迟执行，即只在需要用到某个模块的时候再require） 可以很容易在 Node.js 中运行；
**缺点：**依赖 SPM 打包，模块的加载逻辑偏重；
**实现：Sea.js** ；coolie

### **ES6**

ECMAScript6 标准增加了 JavaScript 语言层面的模块体系定义。[ES6 模块](http://es6.ruanyifeng.com/#docs/module)的设计思想，是尽量的静态化，使得**编译**时就能确定模块的依赖关系，以及输入和输出的变量。CommonJS 和 AMD 模块，都只能在运行时确定这些东西。**但是由于ES6目前无法在浏览器中执行，所以，我们只能通过babel将不被支持的import编译为当前受到广泛支持的 require**。

```js
import "jquery";
export function doStuff() {}
module "localModule" {}
```

优点：

- 容易进行静态分析
- 面向未来的 ECMAScript 标准

缺点：

- 原生浏览器端还没有实现该标准
- 全新的命令字，新版的 Node.js才支持

### commonjs和ES6的区别

- **CommonJS**的`require`语法是同步的，所以就导致了**CommonJS**模块规范只适合用在服务端，而ES6模块无论是在浏览器端还是服务端都是可以使用的，但是在服务端中，还需要遵循一些特殊的规则才能使用 ；

- CommonJS模块输出的是一个值的拷贝，ES6 模块输出的是值的引用；

  ```js
  // lib.js
  var counter = 3;
  function incCounter() {
    counter++;
  }
  module.exports = {
    counter: counter,
    incCounter: incCounter,
  };
  //commonjs
  var mod = require('./lib');
  console.log(mod.counter);  // 3
  mod.incCounter();
  console.log(mod.counter); // 3
  //ES6
  import { counter, incCounter } from './lib';
  console.log(counter); // 3
  incCounter();
  console.log(counter); // 4
  ```

  

- CommonJS 模块是运行时加载，Module被加载的时候执行，加载后缓存（只加载一次，第二次就直接用放到内存中的结果，不重复加载了，第一次加载的时候会执行）。ES6 模块是编译时输出接口,使得对JS的模块进行静态分析成为了可能

- `this`关键词，在ES6模块顶层，`this`指向`undefined`；而CommonJS模块的顶层的`this`指向当前模块

## webpack和gulp的区别

**前提：**

越来越多的网站已经从网页模式进化到了 Webapp 模式。它们运行在现代的高级浏览器里，使用 HTML5、 CSS3、 ES6 等更新的技术来开发丰富的功能，网页已经不仅仅是完成浏览的基本需求，并且webapp通常是一个单页面应用，每一个视图通过异步的方式加载，这导致页面初始化和使用过程中会加载越来越多的 JavaScript 代码，这给前端开发的流程和资源组织带来了巨大的挑战。

如何在开发环境组织好这些碎片化的代码和资源，并且保证他们在浏览器端快速、优雅的加载和更新，就需要一个模块化系统

### webpack打包工具定义

webpack是一个前端模块化方案，更侧重模块打包，我们可以把开发中的所有资源（图片、js文件、css文件等）都看成模块，通过loader（加载器）和plugins（插件）对资源进行处理，打包成符合生产环境部署的前端资源。

**网页中常见的静态资源**

**js**--js，jax，coffee，ts(TypeScript,需要编译为js)

**css**-- css,less,sass

**image**--jpg,png,gif,bmp,svg

**字体文件(Fonts)**--svg,ttf,eot,woff,woff2

**模板文件**--ejs,jade,vue(这是在webpack中定义的组件的方式)

![什么是webpack](https://zhaoda.net/webpack-handbook/images/what-is-webpack.png)

### gulp构建工具定义

gulp强调的是前端开发的工作流程，我们可以通过配置一系列的task，定义task处理的事务（例如文件压缩合并、雪碧图、启动server、版本控制等），然后定义执行顺序，来让gulp执行这些task，从而构建项目的整个前端开发流程。

### 相同功能

| 功能                  | gulp                                                         | webpack                                                      |
| --------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 文件合并与压缩（css） | 使用gulp-minify-css模块 gulp.task('sass',function(){    gulp.src(cssFiles)    .pipe(sass().on('error',sass.logError))    .pipe(require('gulp-minify-css')())    .pipe(gulp.dest(distFolder)); }); | 样式合并一般用到extract-text-webpack-plugin插件， 压缩则使用webpack.optimize.UglifyJsPlugin。 |
| 文件合并与压缩（js）  | 使用gulp-uglify和gulp-concat两个模块                         | js合并在模块化开始就已经做， 压缩则使用webpack.optimize.UglifyJsPlugin |
| sass/less预编译       | 使用gulp-sass/gulp-less 模块                                 | sass-loader/less-loader 进行预处理                           |
| 启动server            | 使用gulp-webserver模块 var webserver =require('gulp-webserver'); gulp.task('webserver',function(){    gulp.src('./')    .pipe(webserver({      host:'localhost',      port:8080,      livereload:true, //自动刷新      directoryListing:{         enable: true,         path:'./'      },    })); }); | 使用webpack-dev-server模块 module.exports = {    ......    devServer: {      contentBase: "build/",      port:8080,      inline: true //实时刷新    } } |
| 版本控制              | 使用gulp-rev和gulp-rev-collector两个模块                     | 将生成文件加上hash值 module.exports = {    ......   output: {     ......     filename: "[name].[hash:8].js"   },    plugins:[      ......      new ExtractTextPlugin(style.[hash].css")    ] } |

### 区别

- gulp严格上讲，模块化不是他强调的东西，他旨在规范前端开发流程。

- webpack更是明显强调模块化开发，而那些文件压缩合并、预处理等功能，不过是他附带的功能。

- Webpack 可以做到按需加载。像 Grunt、Gulp 这类构建工具，打包的思路是：遍历源文件→匹配规则→打包，这个过程中做不到按需加载，即对于打包起来的资源，到底页面用不用，打包过程中是不关心的。Webpack 跟其他构建工具本质上不同之处在于：Webpack 是从入口文件开始，经过模块依赖加载、分析和打包三个流程完成项目的构建。在加载、分析和打包的三个过程中，可以针对性的做一些解决方案，达到按需加载的目的，比如code split（拆分公共代码等）。

## webpack

```js
const path= require('path');
const webpack = require("webpack");
//导入在内存中生成html页面的插件
const htmlWebpackPlugin = require("html-webpack-plugin");
/// 导入每次删除文件夹的插件
 const { CleanWebpackPlugin } = require('clean-webpack-plugin');
// 导入抽取CSS的插件
const ExtractTextPlugin = require("extract-text-webpack-plugin")
// 导入压缩CSS的插件
const OptimizeCssAssetsPlugin = require('optimize-css-assets-webpack-plugin')
//配置文件就是js文件，通过node中的模块操作，向外暴露一个配置对象
module.exports = {
    //决定入口和出口
    entry:{// 配置入口节点
    app: path.join(__dirname, './src/main.js'),
    vendors1: ['jquery'] // 把要抽离的第三方包的名称，放到这个数组中
    }
    output: {
        path:__dirname+'/dist',//指定打包好的文件输出到那个目录中
        filename: 'js/bundle.js'
    },
    devServer:{
        //配置dev-server命令参数的第二种形式
        // "dev": "webpack-dev-server --open --port 3000 --contentBase src --hot"
        open:true,//自动打开浏览器
        port:3000,
        contentBase:'src',//指定托管的根目录
        hot:true,//启动热更新
        inline: true
    },
    plugins:[
        //配置插件的节点
        new webpack.HotModuleReplacementPlugin(),//new一个热更新的模块对象
        new htmlWebpackPlugin({//创建一个在内存中生成一个html的插件
            template:path.join(__dirname,"./src/index.html"),//指定模板页面，会根据路径去生成内存中的页面
            filename:'index123.html',//指定生成页面名称,使用webpack打包可以存放在output.path为dist文件夹下，并自动引用bundle.js
            title:'test',
            inline:true,//实时加载
            minify:{//压缩html文件
                removeComments:true,//移出html中的注释
                collapseWhitespace:false//删除空白符与换行符
            }
        }),
         new CleanWebpackPlugin(),
         new webpack.optimize.CommonsChunkPlugin({
      			name: 'vendors1', // 指定要抽离的入口名称
     			filename: 'js/vendors.js' // 将来再发布的时候，除了会有一个 bundle.js ，还会多一个 vendors.js 的文件，里面存放了所有的第三方包
    }),
    	new webpack.optimize.UglifyJsPlugin({
     			 compress: { // 配置压缩选项
      			  warnings: false // 移除警告
      }
    }),
   		 new webpack.optimize.DedupePlugin({ // 设置为产品上线环境，进一步压缩JS代码
      			'process.env.NODE_ENV': '"production"'
    }),
    	new ExtractTextPlugin("css/styles.css"), // 抽取CSS文件
    	new OptimizeCssAssetsPlugin()// 压缩CSS的插件
    ],
    module:{//这个节点由于配置所有的第三方模块加载器
        rules:[//所有第三方模块的匹配规则
             { test: /\.jsx?$/, use: 'babel-loader', exclude: /node_modules/ },
            {test:/\.css$/,use:['style-loader','css-loader']},
            //使用loader时是从右往左调用的，当调用完毕后会把处理的结果直接交给webpack进行打包合并，最终输出到bundle.js
            {test:/\.less$/,use:['style-loader','css-loader','less-loader']},
            {test:/\.(jpg|png|gif|bmp|jpeg)$/,use:['url-loader?limit=100&name=[hash:8]-[name].[ext]']}
            //limit是给定的值，是图片的大小，单位b，如果limit大于或等于图片的大小则会转换为base64格式的字符串
            //图片使用定义的名称而不是base64，[name].[ext]。相同图片不同路径，为了分清使用[hash:]value,value是1-32
        ]
    }
}

```

### 依赖

#### webpack和webpack-dev-server的区别

**webpack**

一个模块打包器，根据entry指示webpack应该使用哪个模块，来作为构建其内部依赖图的开始。进入入口起点后，webpack 会找出有哪些模块和库是入口起点（直接和间接）依赖的。
每个依赖项随即被处理，最后输出到output字段指定的文件中

**webpack-dev-server**

webpack-dev-server：一个服务器插件，相当于webpack+apache，启动一个web服务并实时更新修改
启动webpack-dev-server后，在目标文件夹中是看不到编译后的文件的，实时编译后的文件都保存到了内存当中。

**区别**

- webpack不会实时更新修改，就只是一个打包工具，webpack-dev-server会实时自动更新修改
- webpack打包输出路径，output字段为path，webpack-dev-server打包输出路径，output字段为publicPath(此值为空时默认是项目根目录，  contentBase:'src',//指定托管的根目录)
- webpack打包输出的文件，是真的存在于物理地址path中，而webpack-dev-server打包输出的文件，是保存在内存中的，在项目目录中是找不到的。

#### html-webpack-plugin插件

webpack-dev-server实现了自动编译刷新浏览器，让编译出来的bundle.js托关于服务器根路径（电脑内存）中去。

html-webpack-plugin会创建一个在内存中生成一个html的插件，帮我们自动引入在内存中打包好的bundle.js文件

# 编码规范

https://www.jianshu.com/p/ad1e46faaea2 

https://blog.csdn.net/userkang/article/details/84305689

每个程序员都有自己的编码习惯，最常见的莫过于：

- 有的人写代码一行代码结尾必须加分号 `;`，有的人觉得不加分号 `;` 更好看；
- 有的人写代码一行代码不会超过 80 个字符，认为这样看起来简洁明了，有的人喜欢把所有逻辑都写在一行代码上，觉得别人看不懂的代码很牛逼；
- 有的人使用变量必然会先定义 `var a = 10;`，而粗心的人写变量可能没有定义过就直接使用 `b = 10;`；

## Lint 的含义

如果你写自己的项目怎么折腾都没关系，但是在公司中老板希望每个人写出的代码都要符合一个统一的规则，这样别人看源码就能够看得懂，因为源码是符合统一的编码规范制定的。

那么问题来了，总不能每个人写的代码老板都要一行行代码去检查吧，这是一件很蠢的事情。凡是重复性的工作，都应该被制作成工具来节约成本。这个工具应该做两件事情：

- 提供编码规范；
- 提供自动检验代码的程序，并打印检验结果：告诉你哪一个文件哪一行代码不符合哪一条编码规范，方便你去修改代码。

Lint 因此而诞生。

Lint 是检验代码格式工具的一个统称，具体的工具有 `Jslint` 、 `Eslint` 等等

## Eslint 

### 含义

> ESLint 是什么呢？
> 是一个开源的 JavaScript 的 linting 工具，使用 [espree](https://link.zhihu.com/?target=https%3A//github.com/eslint/espree) 将 JavaScript 代码解析成抽象语法树 (AST)，然后通过AST 来分析我们代码，从而给予我们两种提示：

1. **代码质量问题：使用方式有可能有问题(problematic patterns)**
2. **代码风格问题：风格不符合一定规则 (doesn’t adhere to certain style guidelines)**

ESLint 可以让程序员在编码的过程中发现问题而不是在执行的过程中。

ESLint 的初衷是为了让程序员可以创建自己的检测规则。ESLint 的所有规则都被设计成可插拔的。为了便于人们使用，ESLint 内置了一些规则，当然，你可以在使用过程中自定义规则。所有的规则默认都是禁用的。

ESLint 使用 **Node.js** 编写，这样既可以有一个快速的运行环境的同时也便于安装。 (重点，**使用eslint必须有package.json文件**)

### 安装

```
npm init
```

 npm 安装 ESLint：

```
$ npm install eslint --save-dev
```

运行 `eslint --init` 之后，`.eslintrc` 文件会在你的文件夹中自动创建

生成流程：https://blog.csdn.net/shenxianhui1995/article/details/103035013

之后，你可以在任何文件或目录上运行ESLint如下：

```
$ ./node_modules/.bin/eslint yourfile.js
```

### eslint配置

https://www.cnblogs.com/jiaoshou/p/11218526.html

1. 一般都采用.eslintrc.*的配置文件进行配置, 如果放在项目的根目录中，则会作用于整个项目。如果在项目的子目录中也包含着.eslintrc文件，则对于子目录中文件的检查会忽略掉根目录中的配置，而直接采用子目录中的配置，这就能够在不同的目录范围内应用不同的检查规则，显得比较灵活。ESLint采用逐级向上查找的方式查找.eslintrc.*文件，当找到带有"root": true配置项的.eslintrc.*文件时，将会停止向上查找。
2. 在 package.json文件里的 eslintConfig 字段进行配置。

```js
module.exports = {
    "globals": {},
    "env": {
        "browser": true,
        "es2021": true
    },
    "extends": "eslint:recommended",
    "parse": "babel-eslint",
    "parserOptions": {
        "ecmaVersion": 12,
        "sourceType": "module"
    },
    "rules": {}
};
```

#### globals

ESLint会检测未声明的额外的全局变量，并发出报错，比如node环境中的process，浏览器环境下的全局变量console，以及我们通过cdn引入的jQuery定义的$等；我们可以在`globals`中进行变量声明：

```json
{
    "globals": {
        // true表示该变量可读写，false表示变量是只读
        "$": true,
        "console": false
    }
}
```

但是node或者浏览器中的全局变量很多，如果我们一个个进行声明显得繁琐，因此就需要用到我们的`env`，这是对环境定义的一组全局变量的预设。

#### env

使用 `env` 属性来指定要启用的环境，将其设置为 `true`，以保证在进行代码检测时不会把[这些环境](http://eslint.cn/docs/user-guide/configuring#specifying-environments)预定义的全局变量识别成未定义的变量而报错

```
"env": {
    "browser": true,
    "commonjs": true,
    "es6": true,
    "jquery": true
}
```

#### 插件plugins

##### eslint-plugin-html

```
npm install --save-dev eslint-plugin-html
```

```js
{
    "plugins": [
        "html"
    ]
}
```

#### 解析器

##### parser

[Babel-ESLint](https://www.npmjs.com/package/babel-eslint) - 一个对[Babel](https://babeljs.io/)解析器的包装，使其能够与 ESLint 兼容

##### parserOptions

默认情况下，ESLint 支持 ECMAScript 5 语法，如果你想启用对 ECMAScript 其它版本和 JSX 等的支持，ESLint 允许你使用 `parserOptions` 属性进行指定想要支持的 JavaScript [语言选项](http://eslint.cn/docs/user-guide/configuring#specifying-parser-options)

```json
{
  "parser": "babel-eslint",
  "parserOptions": {
    // 代码模块类型，可选script(默认)，module
    "sourceType": "module",
    // es版本号，默认为5，可以使用年份2015（同6）
    "ecamVersion": 6,
    // es 特性配置
    "ecmaFeatures": {
        "globalReturn": true, // 允许在全局作用域下使用 return 语句
        "impliedStrict": true, // 启用全局 strict mode 
        "jsx": true // 启用 JSX
    }
  },
}
```

#### 配置规则

**启用的规则及其各自的错误级别**

在上文的配置文件中， `"extends": "eslint:recommended"` 选项表示启用推荐规则，在推荐规则的基础上我们还可以根据需要使用 `rules` 新增自定义规则，每个规则的第一个值都是代表该规则检测后显示的错误级别：

- `"off"` 或 `0` - 关闭规则
- `"warn"` 或 `1` - 将规则视为一个警告
- `"error"` 或 `2` - 将规则视为一个错误

```json
 "rules":{
        // 代码缩进，使用tab缩进，switch语句的case缩进级别，1表示2个空格
        "indent": ["error", "tab", { "SwitchCase": 1 }],
        // 引号，双引号
        "quotes": ["error", "double"],
        // 在语句末尾使用分号
        "semi": ["error", "always"]
    }
```

#### 扩展extends

如果每条规则都需要团队协商配置还是比较繁琐的，在项目开始配置时，我们可以先使用一些业内已经成熟的、大家普遍遵循的编码规范（最佳实践）；我们可以通过`extends`字段传入一些规范，它接收String/Array：

```json
{
    "extends": [
        "eslint:recommended",
        "plugin:vue/essential",
        "@vue/prettier",
        "eslint-config-standard"
    ]
}
```

extends可以使用以下几种类型的扩展：

- eslint：开头的ESLint官方扩展，有两个：`eslint:recommended`（推荐规范）和`eslint:all`（所有规范）。
- plugin：开头的扩展是插件类型扩展
- eslint-config：开头的来自npm包，使用时可以省略`eslint-config-`，比如上面的可以直接写成`standard`
- @：开头的扩展和eslint-config一样，是在npm包上面加了一层作用域scope

> 需要注意的是：多个扩展中有相同的规则，以后面引入的扩展中规则为准。

`eslint:recommended`推荐使用的规则在规则列表的右侧用`绿色√`标记。



#### Tips

- eslint在setting.json中配置和.eslintrc.js文件配置区别

  https://segmentfault.com/q/1010000023094556

  setting.json里面配的是vscode对eslint插件的一些配置，而.eslintrc里面配的是对代码规范的配置。目标不一样。vscode的所有配置都针对于插件或者vscode自身的。除了特别指定，这个 eslint 配置文件将会覆盖掉 vscode 的 setting.json 中 eslint 相关的配置。

## Prettier

它是**代码格式化工具**，用来做代码格式化，有了Prettier之后，它能去掉原始的代码风格，确保团队的代码使用统一相同的格式，修复规则可自定义。

```js
    //  #让prettier使用eslint的代码格式进行校验 
    "prettier.eslintIntegration": true,
```

# git

## git如何创建多个ssh

### 1.清除原有的设置

**初次使用git请跳过此步骤**

如果之前对git设置过global信息，则需要先清除这些信息，通过如下指令：

查看Git所有配置

```
git config --list
```

查看当前用户（**local**）配置

```
git config --local  --list
或者
cat .git/config
```

查看`user.name`

```
git config user.name
```

查看`user.email`

```
git config user.email
```

**删除**全局配置项

```
git config --global --unset user.name
```

```
$ git config --global --unset user.name “username”
$ git config --global --unset user.email "email"
```

### 2.ssh配置

1. 配置用户信息	

```
cd ~/workspace/gitlab
git init
git config --local user.name ‘gitlab‘//local局部 global
git config --local user.email ‘gitlab@company.com‘
```

2.	生成ssh key

```
ssh-keygen -t rsa -C "email"
```

 当命令行出现 Enter file in which to save the key (~/.ssh/id_rsa):  

 它会提示你输入一个保存key的路径/文件名，默认创建文件名id_rsa（若有多个邮箱，则创建不同的文件名）

 在.ssh文件中找到创建的id_rsa_pub并复制里面的内容，在远程的设置的密钥（key）里面粘贴

3.	配置config文件(id_rsa文件同级目录下)

```
#Host 它涵盖了下面一个段的配置，我们可以通过他来替代将要连接的服务器地址。
#HostName    真正连接的服务器地址
#User是本地ssh-agent与github服务器建立SSH连接时采用的用户名，IdentityFile是对应的私钥文件


#ssh -T User@Host	判断连接是否成功

# gitlab
Host git.lab
HostName gitlab.com
User git
PreferredAuthentications publickey
IdentityFile ~/.ssh/id_lab

# github
Host git.hub
HostName github.com
User git
PreferredAuthentications publickey
IdentityFile ~/.ssh/id_rsa
```

4. 本地仓库与远程仓库关联：

   ```
   git remote add origin(设置的远程库名) User@Host:用户名/仓库名
   
   或者直接 git clone 链接(一般是master上的分支)
   ```

5. 测试连接成功

   ```
   ssh -T User@Host
   ```
## git 指令

git init 初始化版本库（clone下来的不用初始化）

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/QhRDUrJbPe6737sZ1ptKUEQcY6YOcKFqqqdv3riaAEJYVibl3GUgmRTiaH5sldypibNN7Zzk3Zqv9lMCAAsvT4vVQw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:67%;" />

首先**工作区**就是我们当前的文件目录，我们改完代码，用`git add`命令把当前文件加入**暂存区**，然后`git commit`把**暂存区**生成的快照提交到**本地仓库**，最后再用`git push`命令把**本地仓库**的提交复制到**远程仓库**，也就是`Github`之类的在线仓库。



git add 文件名      						                 放入暂存区stage

git commit -m "提交的说明message"		放入分支里

git commit  -am， add和commit的合并，便捷写法

git commit --amend  尝试重新提交(漏掉了几个文件没有添加，或者**提交信息commit message**写错)，新增的`commit`会代替原来的`commit`的位置，而旧`commit`则被抛弃掉

**commit规范**

```
feat:     A new feature
fix:      A bug fix
docs:     Documentation only changes
style:    Changes that do not affect the meaning of the code (white-space, 				  formatting,missing semi-colons, etc)
refactor: A code change that neither fixes a bug nor adds a feature
perf:     A code change that improves performance
test:     Adding missing tests or correcting existing tests
```

### 分支的操作

分支规范https://zhuanlan.zhihu.com/p/108385922

```
git checkout -b dev 或者git switch -c dev    创建并切换该分支
git branch dev 								创建分支
git branch -d dev							删除分支
git branch -D dev							强行删除一个没有合并的分支    
git checkout master							切换分支
                                                                                                  
git pull orgin 分支名					   拉取并合并分支
pull= fetch + merge
git rebase 分支							合并分支
git push orgin dev 						 传分支到dev上
git branch -vv                           查看关联关系

git checkout -b dev origin/dev	         直接拉取远程的分支，创建为本地的分支

如果您想要为此分支创建跟踪信息，您可以执行：
git branch --set-upstream-to=origin/<分支> master

git branch					查看本地分支
git branch -r			    查看远程分支
git branch -a 			    查看所有分支（包括远程分支和本地分支）
git branch -a | grep paynicorn2-repay-notice 查询指定分支(本地和远程的)
```

### 远程的操作

```
远程分支的移除
 git remote rm paul				
 git push origin --delete main
 
//https://blog.csdn.net/wangqingpei557/article/details/53147086
删除远程分支，git branch -a,还是可以看到远程的分支
解决：git remote prune origin 

git remote rename pb paul       	     pb 重命名为 paul
git push --set-upstream origin wangxiao	 将本地的分支推送远程上
```

### 查看信息

<img src="https://img2018.cnblogs.com/blog/333765/202001/333765-20200111163049190-252688967.png" alt="img" style="zoom: 67%;" />

```
git status 					  查看文件状态（是否被add或者commit）
使用 git status -s 命令或 git status –short 命令，你将得到一种更为紧凑的格式输出

git diff 						 		    区和的暂存区差异
git diff HEAD								显示工作区与当前分支最新commit之间的差异
git diff --cached 							显示暂存区和上一个commit的差异
git diff branch-1 branch-2 	[filename]		比较两个分支(filename)的不同
git diff commit1..commit2  					查看两个 commit 的对比
git ls-files								查看暂存区的文件
git diff origin/branchname..branchname 		查看远程分支和本地分支的对比

git log							查看提交日志，每一次提交都有对应的 commit id 和 commit message(看不出来被删除的commitid)
									  可以加上参数  --pretty=oneline，只会显示版本号和提交时的备注信息
git log  -p					  用来显示每次提交的内容差异									  
git reflog					  记录操作记录(包括已经被删除的 commit 记录和 reset 的操作)

git remote -v				查看关联的远程仓库url
cat .git/HEAD			   查看当前 HEAD 指向
```

### 回退系列

```
git reset --hard HEAD^					    回退到上一个版本
git reset --hard HEAD~1					    回退到上一个版本
git reset --hard id(前6位就行)	        	 回退到指定版本

git checkout .										   清空工作区改动
git checkout -- 文件名 					  

当你开始修改一个文件后，还没有执行 git add命令前(此时还在工作区）,想撤销对这个文件的改动，可以使用git checkout -- 文件名 
一旦你使用了 git add命令将文件添加到暂存区，此时不想改这个文件了，需要用git reset HEAD filename(git reset HEAD .)把文件移会到工作区，再使用第一步的git checkout -- 文件名 撤销工作区改动
```

### 文件的操作

```
git rm 文件名									删除文件，若误删，可以使用git checkout -- 文件名 
rm -rf  `git status | grep app/code`
cut 文件名										 获取文件内容
```

### git stash

```
git stash	将当前修改的内容存储
git stash apply		恢复不删除
git satsh pop		恢复并删除
git stash list
git stash apply stash@{}
```

### git rebase 

https://www.cnblogs.com/tian874540961/p/12172900.html

https://blog.csdn.net/hudashi/article/details/7664631/

https://www.cnblogs.com/hujunzheng/p/9732936.html

<img src="https://qboshi.oss-cn-hangzhou.aliyuncs.com/pic/086ccdee-4f40-4a8c-99c8-886bc672f0d8.jpg" alt="img" style="zoom:50%;" />

当我开发完D后，准备push到远端master时，git会进行检查：**远端master的最新节点是否是节点D的基点，即检查远端master的基点是否是节点C**，如果是，则可以直接push，如果不是，也就是上图的情况：在你push之前远端master已经被他人提交了E和F节点，这时可以执行`git pull -r`

<img src="https://qboshi.oss-cn-hangzhou.aliyuncs.com/pic/88729b51-5f43-42a5-bd69-9c39f863ab92.jpg" alt="img" style="zoom:50%;" />

git会以F节点作为新的基点，与D节点的代码进行融合，如果此时出现**冲突**，那么你就会被移到临时解冲突的分支，需要人工解冲突，解完后执行`git add -A`保存操作，再执行`git rebase --continue`继续后续操作，你可能会遗漏某一处冲突，这个完全不同担心，`git rebase --continue`会帮你检查是否解决完成，如果没有完成则不会让你回到正常分支。

<img src="https://qboshi.oss-cn-hangzhou.aliyuncs.com/pic/beb6433f-49e8-4b42-b821-32a7350f2cc7.jpg" alt="img" style="zoom:50%;" />

此时我再执行`git push`，就可以顺利将D节点提交到远端master上去了：

<img src="https://qboshi.oss-cn-hangzhou.aliyuncs.com/pic/469b4e16-c88d-4f71-9dde-c7eb432b7a78.jpg" alt="img" style="zoom:50%;" />

这同理本地基于master分支创建dev分支，master拉取远程代码后(其他人push了代码到远程master)，本地的master领先与dev分支，所以需要rebase，不然会污染了 commit 记录

```
git rebase --edit-todo
git rebase —abort 都可以用 --abort 参数来终止 rebase 的行动，并且分支会回到 rebase 开始前的状态。
```

- #### **危险操作**

  你的同事也在 相同分支 上开发，那么当他 pull 远程 master 的时候，就会有丢失提交纪录。
  
- 合并多个提交

  ```
  git rebase -i HEAD~2
  将第二行的 pick 改为 s “s” 为 “squash” 的缩写
  ```

## Tips

- git忽略文件权限的改变
  git config core.filemode false
  
- 本次提交被远程仓库拒绝了，因为当前分支无法与远程仓库对应起来。远程仓库对应分支默认有个指针指向最新提交到仓库的 commit ，而所有的本地仓库的分支都可以看做是从这个 commit 分散开来的。也就是本地分支的最后一次 push 到仓库的 commit 一定与仓库对应分支的最新一次 commit 是相同的，否则就无法对接。也就是会出现上面的错误提示。如果是正常 push 到仓库，正确的完成 commit 更新，那么这次更新就是一个 `fast-forward` 更新,而如果不理会错误警告用本地更新强制覆盖仓库，就是一次 `no-fast-forward` 更新，很明显，**`no-fast-forward` 更新会导致记录丢失**。
  
  ![image-20201217103256376](/home/silk/.config/Typora/typora-user-images/image-20201217103256376.png)

- git 换行符LF与CRLF转换问题https://blog.csdn.net/qq_22978533/article/details/78145935

  在各操作系统下，文本文件所使用的换行符是不一样的。UNIX/Linux/ Mac OS使用的是 LF，但 DOS/Windows 一直使用 CRLF作为换行符。Git提供了一个“换行符自动转换”功能。这个功能默认处于“自动模式”，当你在签出文件时，它试图将 UNIX 换行符（LF）替换为 Windows 的换行符（CRLF）；当你在提交文件时，它又试图将 CRLF 替换为 LF。Git 的“换行符自动转换”功能听起来似乎很智能、很贴心，因为它试图一方面保持仓库内文件的一致性（UNIX 风格），一方面又保证本地文件的兼容性（Windows 风格）。但遗憾的是，这个功能是有 bug 的，而且在短期内都不太可能会修正。

  ```
  #提交时转换为LF，检出时不转换
  git config --global core.autocrlf input
  
  #提交检出均不转换
  git config --global core.autocrlf false
  SafeCRLF
  #拒绝提交包含混合换行符的文件
  git config --global core.safecrlf true
  
  #允许提交包含混合换行符的文件
  git config --global core.safecrlf false
  
  #提交包含混合换行符的文件时给出警告
  git config --global core.safecrlf warn
  
  ```


- 解决Git在添加ignore文件之前就提交了项目无法再过滤问题

  ```matlab
  首先为避免冲突需要先同步下远程仓库
  $ git pull
  在本地项目目录下删除缓存
  $ git rm -r --cached .
  新建.gitignore文件
  在项目的根目录下面新建.gitignore文件并添加相应的过滤规则
  
  再次add所有文件
  输入以下命令，再次将项目中所有文件添加到本地仓库缓存中
  $ git add .
  
  再次添加commit
  这次commit是为了说明添加ignore文件的。
  $ git commit -m "add ignore"
  最后提交到远程仓库即可
  $ git push
  ```

- fatal: 当前分支 master 没有对应的上游分支。
  为推送当前分支并建立与远程上游的跟踪，使用

      git push --set-upstream origin master

- 无法连接到仓库,尝试重新连接

  ```
  git remote rm origin删除远程origin
  git remote add origin git@git.hub.bundle:bibo72/bundleb2b-v3.0-storefront.git
  ```

# npm

## 插件

- 将DOM转化成canvas对象

  http://html2canvas.hertzen.com/dist/html2canvas.min.js

- 将canvas生成照片

  HTTP://github.com/randreucetti/canvas2image

- 一个用于将文本复制到剪贴板的 JS 库

  https://github.com/zenorocha/clipboard.js

## 命令

查看当前项目安装过的依赖模块
npm list --depth 0

查看全局安装过的依赖模块
npm list -g --depth 0

清理缓存命令：

- 局部

```
npm cache clean --force
```

- 全局

  ```
  cd ~/.npm
  du -sh * 
  rm -rf _cacache   
  ```

  

